{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kWXrMRuoX3bI"},"outputs":[],"source":["%pip install transformers sentencepiece datasets asian-bart wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kyIXC_qkQPZJ"},"outputs":[],"source":["import os\n","if \"drive\" not in os.listdir(\"/content\") :\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/NLP_Project_3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MLHd1CQoXii"},"outputs":[],"source":["!wandb login\n","\n","fine_tuned_model_name = \"write_your_model_name\"\n","\n","import wandb\n","wandb.init(project = \"Goorm_3rd_project\", entity = \"2nd_group\", name = fine_tuned_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaZF1awqQYZZ"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import json\n","import datasets\n","import random\n","\n","from transformers import MBartForConditionalGeneration, MBartTokenizer, DataCollatorForSeq2Seq, AutoTokenizer, get_cosine_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from collections import defaultdict, Counter, deque\n","from tqdm import tqdm\n","\n","from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n","from transformers.models.bart.modeling_bart import shift_tokens_right\n","\n","SEED = 20220819\n","BACKBONE = \"hyunwoongko/asian-bart-ecjk\"\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if \"cuda\" in DEVICE.type :\n","    torch.cuda.set_device(DEVICE)\n","print(DEVICE)\n","\n","model = AsianBartForConditionalGeneration.from_pretrained(BACKBONE)\n","model.train()\n","model = model.to(DEVICE)\n","\n","tokenizer = AutoTokenizer.from_pretrained(BACKBONE, src_lang=\"en_XX\", tgt_lang=\"ko_KR\")\n","\n","model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])\n","print(\"# of params in model :\", params)"]},{"cell_type":"code","source":["original_train = utils.load_parallel(\"../RawData\")"],"metadata":{"id":"UWyvF0F3_y_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iu6hahPdan1Z"},"outputs":[],"source":["batch_size = 16\n","collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model = model, return_tensors = \"pt\")\n","\n","train_data = utils.get_dataset(original_train.loc[original_train.loc[:, \"type\"] == \"train\", :], tokenizer, collator, batch_size, True, \"en\", \"ko\")\n","valid_data = utils.get_dataset(original_train.loc[original_train.loc[:, \"type\"] == \"valid\", :], tokenizer, collator, batch_size * 2, True, \"en\", \"ko\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gNUCKLIeg_B"},"outputs":[],"source":["learning_rate = 1e-4\n","epochs = 3\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, eps = 1e-6, weight_decay = 0.02)\n","# lr_scheduler = get_cosine_schedule_with_warmup(optimizer = optimizer,\n","#                                                num_warmup_steps = int(len(train_data) * epochs * 0.02),\n","#                                                num_training_steps = len(train_data) * epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LD9yLX5oiR3"},"outputs":[],"source":["wandb_config = {\n","    \"learning_rate\" : learning_rate,\n","    \"batch_size\" : batch_size,\n","    \"backbone\" : BACKBONE,\n","    \"epochs\" : epochs\n","}\n","\n","wandb.config.update(wandb_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y32Xa5KXYXm0"},"outputs":[],"source":["scaler = torch.cuda.amp.GradScaler()\n","wandb.watch(model, log = \"all\", log_freq = 500)\n","\n","valid_check_period = 5000\n","early_stopping = utils.EarlyStopping(path = \"../Model/parallel_corpus_eng2kor_checkpoint\", patience = 1, verbose = True)\n","halt = False\n","\n","step = 0\n","for epoch in range(epochs) :\n","    cum_loss = deque(maxlen = 20)\n","    curr_loss = []\n","\n","    with tqdm(train_data, unit = \" batch\") as tepoch :\n","        curr_loss.clear()\n","        model.train()\n","\n","        for i, batch in enumerate(tepoch) :\n","            step += 1\n","            optimizer.zero_grad()\n","            tepoch.set_description(f\"Train Epoch {epoch}\")\n","\n","            batch = {k : v.to(DEVICE) for k, v in batch.items()}\n","\n","            with torch.cuda.amp.autocast() :\n","                outputs = model(**batch)\n","                loss = outputs[\"loss\"]\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            # lr_scheduler.step()\n","\n","            cum_loss.append(loss.item())\n","            curr_loss.append(loss.item())\n","\n","            del batch, outputs, loss\n","\n","            tepoch.set_postfix(loss = sum(cum_loss) / len(cum_loss))\n","\n","            wandb.log({\"train_loss\" : sum(cum_loss) / len(cum_loss),\n","                       \"lr\" : optimizer.state_dict()[\"param_groups\"][0]['lr'],\n","                       \"train_step\" : step})\n","\n","\n","            if not step % valid_check_period :\n","                model.eval()\n","                val_losses = []\n","                with torch.no_grad() :\n","                    for j, val_batch in enumerate(valid_data) :\n","                        val_batch = {k : v.to(DEVICE) for k, v in val_batch.items()}\n","                        with torch.cuda.amp.autocast() :\n","                            val_outputs = model(**val_batch)\n","                            val_loss = val_outputs[\"loss\"]\n","                        val_losses.append(val_loss.item())\n","\n","                        del val_batch, val_outputs, val_loss\n","                \n","                wandb.log({\"valid_loss\" : sum(val_losses) / len(val_losses),\n","                           \"valid_step\" : step // valid_check_period})\n","\n","                early_stopping(sum(val_losses) / len(val_losses), model)\n","\n","                if early_stopping.early_stop:\n","                    print(\"Early stopping\")\n","                    halt = True\n","                    break\n","                else :\n","                    model.train()\n","\n","        print(\"Train loss : \", sum(curr_loss) / len(curr_loss))\n","\n","    if halt :\n","        break\n","    curr_loss.clear()\n","    cum_loss.clear()\n","\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nlrDenBHnLT"},"outputs":[],"source":["model.save_pretrained(\"../Model/large_batch_eng2kor\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"eng2kor_basemodel.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.13 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
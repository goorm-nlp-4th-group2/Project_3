{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Top2vvbpqpa5"},"outputs":[],"source":["%pip install transformers sentencepiece datasets asian-bart"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOLXB7SGqzH1"},"outputs":[],"source":["import os\n","if \"drive\" not in os.listdir(\"/content\") :\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/NLP_Project_3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaP_BqpPq0gZ"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import json\n","import datasets\n","import random\n","\n","from transformers import DataCollatorForSeq2Seq, AutoTokenizer\n","from collections import defaultdict, Counter, deque\n","from tqdm import tqdm\n","from asian_bart import AsianBartTokenizer, AsianBartForConditionalGeneration\n","\n","SEED = 20220819\n","BACKBONE = \"hyunwoongko/asian-bart-ecjk\"\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if \"cuda\" in DEVICE.type :\n","    torch.cuda.set_device(DEVICE)\n","print(DEVICE)\n","\n","model = AsianBartForConditionalGeneration.from_pretrained(\"../Model/large_batch_kor2eng/\")\n","model.train()\n","model = model.to(DEVICE)\n","\n","tokenizer = AutoTokenizer.from_pretrained(BACKBONE, src_lang=\"ko_KR\", tgt_lang=\"en_XX\")"]},{"cell_type":"code","source":["back_translation_data = pd.read_csv(\"../RawData/monolingual.csv\")\n","back_translation_data = back_translation_data.loc[back_translation_data.sentence.str.len() < 100, :].rename({\"sentence\" : \"ko\"}, axis = \"columns\")"],"metadata":{"id":"RQjOIqnEXJpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Arh-ehSnrMvO"},"outputs":[],"source":["batch_size = 32\n","collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model = model, return_tensors = \"pt\")\n","\n","inference_data = utils.get_dataset(back_translation_data, tokenizer, collator, batch_size, False, \"ko\", None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jWekCjVrUCL"},"outputs":[],"source":["model.eval()\n","generated = []\n","with torch.no_grad() :\n","    with tqdm(inference_data, unit = \" batch\") as tepoch :\n","        for i, inference_batch in enumerate(tepoch) :\n","            inference_batch = {k : v.to(DEVICE) for k, v in inference_batch.items()}\n","            with torch.cuda.amp.autocast() :\n","                inference_output = model.generate(inference_batch[\"input_ids\"], max_length = 100, num_beams = 7, no_repeat_ngram_size = 2, decoder_start_token_id = tokenizer.lang_code_to_id[\"en_XX\"])\n","            generated += tokenizer.batch_decode(inference_output, skip_special_tokens = True, clean_up_tokenization_spaces = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57PuLPMcsuI_"},"outputs":[],"source":["back_translation_data.loc[:, \"inferenced\"] = generated\n","back_translation_data.loc[:, \"inferenced\"] = back_translation_data.inferenced.str.replace(\" \", '').str.replace(\"â–\", ' ').str.strip()"]},{"cell_type":"code","source":["back_translation_data.to_csv(\"../RawData/generated_eng_data_from_kor.csv\", index = False)"],"metadata":{"id":"3tqfyYmCalOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"UMES73bf3Ij8"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"generate_eng_data_from_kor.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_quantization.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyObFwiP5owT98B5zpryBqc6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["%pip install transformers asian-bart"],"metadata":{"id":"zj_gJUGpzKpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","if \"drive\" not in os.listdir(\"/content\") :\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/NLP_Project_3\")"],"metadata":{"id":"4TJJCbOs0THL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ux0MYV_0zEdH"},"outputs":[],"source":["import torch\n","import time\n","import gc\n","\n","from transformers import AutoTokenizer, AutoConfig\n","from asian_bart import AsianBartForConditionalGeneration\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if \"cuda\" in DEVICE.type :\n","    torch.cuda.set_device(DEVICE)\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"hyunwoongko/asian-bart-ecjk\", src_text = \"ko_KR\", tgt_text = \"en_XX\")\n","\n","model = AsianBartForConditionalGeneration.from_pretrained(\"./Model/large_batch_kor2eng\")\n","\n","quantized_model = torch.quantization.quantize_dynamic(\n","    model, {torch.nn.Linear}, dtype=torch.qint8\n",")"]},{"cell_type":"code","source":["def print_size_of_model(model):\n","    torch.save(model.state_dict(), \"temp.p\")\n","    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n","    os.remove('temp.p')\n","\n","print_size_of_model(model)\n","print_size_of_model(quantized_model)"],"metadata":{"id":"_w3N61qMzH3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantized_model.config.save_pretrained(\"./Model/quantized_kor2eng_config\")\n","torch.save(quantized_model.state_dict(), \"./Model/quantized_kor2eng\")"],"metadata":{"id":"B42AqhDgMWDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"hyunwoongko/asian-bart-ecjk\", src_text = \"ko_KR\", tgt_text = \"en_XX\")\n","config = AutoConfig.from_pretrained(\"./Model/quantized_kor2eng_config\")\n","dummy_model = AsianBartForConditionalGeneration(config)"],"metadata":{"id":"BfoJ_8bmM7UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reconstructed_quantized_model = torch.quantization.quantize_dynamic(dummy_model, {torch.nn.Linear}, dtype = torch.qint8)\n","del dummy_model, config\n","gc.collect()\n","reconstructed_quantized_model.load_state_dict(torch.load(\"./Model/quantized_kor2eng\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwhzLZXBNheg","executionInfo":{"status":"ok","timestamp":1660568873314,"user_tz":-540,"elapsed":17277,"user":{"displayName":"박정민","userId":"11203274198292799302"}},"outputId":"f168deb2-8ead-4aa0-bca4-3d0d254f9d56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def time_model_evaluation(model, tokenizer, device):\n","    eval_start_time = time.time()\n","    inputs = tokenizer([\"안녕하세요.\", \"만나서 반갑습니다.\", \"속도 시험 중 입니다.\", \"자료가 많아질 수록 속도 차이가 많이 나겠죠?\"], return_tensors = \"pt\", padding = True, max_length = 100).input_ids.to(device)\n","    result = model.generate(inputs, max_length = 100)\n","    eval_end_time = time.time()\n","    eval_duration_time = eval_end_time - eval_start_time\n","    print(tokenizer.batch_decode(result, skip_special_tokens = True, clean_up_tokenization_spaces = True))\n","    print(\"Evaluate total time (seconds): {0:.1f}\".format(eval_duration_time))\n","\n"],"metadata":{"id":"Dq2Iw_Nt1Znn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inference on GPU\n","time_model_evaluation(model.to(DEVICE), tokenizer, DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtdiW4zK2NU-","executionInfo":{"status":"ok","timestamp":1660569029127,"user_tz":-540,"elapsed":4,"user":{"displayName":"박정민","userId":"11203274198292799302"}},"outputId":"362de99d-e05f-45cd-9005-4ca864633d56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"]},{"output_type":"stream","name":"stdout","text":["['▁Hello.', \"▁It's ▁nice ▁to ▁meet ▁you.\", \"▁I'm ▁taking ▁a ▁speed ▁test.\", '▁The ▁more ▁material, ▁the ▁higher ▁the ▁speed ▁difference, ▁right?']\n","Evaluate total time (seconds): 0.3\n"]}]},{"cell_type":"code","source":["# 동적 양자화를 거친 INT8 BERT 모델 평가\n","time_model_evaluation(reconstructed_quantized_model, tokenizer, \"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GT0EgKPK2TQj","executionInfo":{"status":"ok","timestamp":1660569032794,"user_tz":-540,"elapsed":1725,"user":{"displayName":"박정민","userId":"11203274198292799302"}},"outputId":"b09632e2-7f2a-4ff8-9fe2-b5a49f1f6ec9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2340: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"]},{"output_type":"stream","name":"stdout","text":["['▁Hello.', \"▁It's ▁nice ▁to ▁meet ▁you.\", \"▁I'm ▁taking ▁a ▁speed ▁test.\", '▁The ▁more, ▁and ▁the ▁s hor ter ▁the ▁speed ▁difference ▁will ▁be, ▁right?']\n","Evaluate total time (seconds): 1.4\n"]}]}]}